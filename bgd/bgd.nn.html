<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bgd.nn module &mdash; Beyond Gradient Descent 0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="bgd.optimizers module" href="bgd.optimizers.html" />
    <link rel="prev" title="bgd.initializers module" href="bgd.initializers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Beyond Gradient Descent
          </a>
              <div class="version">
                0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../math/mathematical_framework.html">Mathematical Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure.html">Structure</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">bgd</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="bgd.html">bgd package</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="bgd.html#subpackages">Subpackages</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="bgd.html#submodules">Submodules</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="bgd.batch.html">bgd.batch module</a></li>
<li class="toctree-l4"><a class="reference internal" href="bgd.cost.html">bgd.cost module</a></li>
<li class="toctree-l4"><a class="reference internal" href="bgd.errors.html">bgd.errors module</a></li>
<li class="toctree-l4"><a class="reference internal" href="bgd.initializers.html">bgd.initializers module</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">bgd.nn module</a></li>
<li class="toctree-l4"><a class="reference internal" href="bgd.optimizers.html">bgd.optimizers module</a></li>
<li class="toctree-l4"><a class="reference internal" href="bgd.utils.html">bgd.utils module</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Beyond Gradient Descent</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">bgd</a></li>
          <li class="breadcrumb-item"><a href="bgd.html">bgd package</a></li>
      <li class="breadcrumb-item active">bgd.nn module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/bgd/bgd.nn.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-bgd.nn">
<span id="bgd-nn-module"></span><h1>bgd.nn module<a class="headerlink" href="#module-bgd.nn" title="Permalink to this headline"></a></h1>
<p>This module contains the <a class="reference internal" href="#bgd.nn.NeuralStack" title="bgd.nn.NeuralStack"><code class="xref py py-class docutils literal notranslate"><span class="pre">bgd.nn.NeuralStack</span></code></a>
class that represents a linear neural network (LNN).</p>
<p>Any other model of neural nets shall be written down here.</p>
<dl class="py class">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bgd.nn.</span></span><span class="sig-name descname"><span class="pre">NeuralStack</span></span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Sequential model that can be viewed as a stack of layers.
Backpropagation is simplified because the error gradient
with respect to the parameters of any layer is the gradient
of a composition of functions (defined by all successor layers)
and is decomposed using the chain rule.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.layers">
<span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#bgd.nn.NeuralStack.layers" title="Permalink to this definition"></a></dt>
<dd><p>List of layers, where layers[0] is the input layer and
layers[-1] is the output layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.batch_op">
<span class="sig-name descname"><span class="pre">batch_op</span></span><a class="headerlink" href="#bgd.nn.NeuralStack.batch_op" title="Permalink to this definition"></a></dt>
<dd><p>Batching method to use in order to perform one step of the
backpropagation algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="bgd.batch.html#bgd.batch.Batching" title="bgd.batch.Batching"><code class="xref py py-class docutils literal notranslate"><span class="pre">bgd.batch.Batching</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.cost_op">
<span class="sig-name descname"><span class="pre">cost_op</span></span><a class="headerlink" href="#bgd.nn.NeuralStack.cost_op" title="Permalink to this definition"></a></dt>
<dd><p>Error metric to use in order to evaluate model performance.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="bgd.cost.html#bgd.cost.Cost" title="bgd.cost.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">bgd.cost.Cost</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.optimizer">
<span class="sig-name descname"><span class="pre">optimizer</span></span><a class="headerlink" href="#bgd.nn.NeuralStack.optimizer" title="Permalink to this definition"></a></dt>
<dd><p>Optimizer to use in order to update the parameters of the
model during backpropagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="bgd.optimizers.html#bgd.optimizers.Optimizer" title="bgd.optimizers.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">bgd.optimizers.Optimizer</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.activate_dropout">
<span class="sig-name descname"><span class="pre">activate_dropout</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.activate_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.activate_dropout" title="Permalink to this definition"></a></dt>
<dd><p>Activates the Dropout layers (for training phase).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">component</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.add" title="Permalink to this definition"></a></dt>
<dd><p>Adds a component to the model: it can be either a layer
or a special component like an optimizer. Some components
are mandatory to train the model. The architecture of the
model is defined by the layers that are provided to this
method. Thus, the order is taken into account when adding
layers. However, the order has no importance when adding
special components like optimizers, error metrics, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>component</strong> (<em>object</em>) – Component to add to the model (Layer or special component).</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="bgd.errors.html#bgd.errors.WrongComponentTypeError" title="bgd.errors.WrongComponentTypeError"><strong>WrongComponentTypeError</strong></a> – If the type of component is not recognized.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.check_components">
<span class="sig-name descname"><span class="pre">check_components</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.check_components"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.check_components" title="Permalink to this definition"></a></dt>
<dd><p>Verifies that all the components are set properly so
that training is possible. If either the batch method, the
optimizer or the error function is missing, an exception
will be raised.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference internal" href="bgd.errors.html#bgd.errors.RequiredComponentError" title="bgd.errors.RequiredComponentError"><strong>RequiredComponentError</strong></a> – If any component of the model has not been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.deactivate_dropout">
<span class="sig-name descname"><span class="pre">deactivate_dropout</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.deactivate_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.deactivate_dropout" title="Permalink to this definition"></a></dt>
<dd><p>Deactivates the Dropout layers (after training phase).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.eval" title="Permalink to this definition"></a></dt>
<dd><p>Feeds a sample (or batch) to the model linearly from any
layer to any layer. By default, X is propagated through the
entire stack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – The sample (or batch of samples) to feed to the model.</p></li>
<li><p><strong>start</strong> (<em>int</em>) – Index of the layer where X is to be fed.</p></li>
<li><p><strong>stop</strong> (<em>int</em>) – Index of the last layer of propagation (-1 for last layer).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>out:</dt><dd><p>Output of the propagation of X through each layer
of the model.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.eval_loss">
<span class="sig-name descname"><span class="pre">eval_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.eval_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.eval_loss" title="Permalink to this definition"></a></dt>
<dd><p>Returns the loss value of the output computed by the model
with respect to the actual output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_y</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – True labels of the samples.</p></li>
<li><p><strong>predictions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – Labels predicted by the model.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – L2 regularization alpha term (0 if no L2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>loss:</dt><dd><p>The value of the loss function.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.get_accuracy">
<span class="sig-name descname"><span class="pre">get_accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.get_accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.get_accuracy" title="Permalink to this definition"></a></dt>
<dd><p>Returns the accuracy of the provided dataset on the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>AttributeError</strong> – </p>
</dd>
</dl>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">bgd.ClassificationCost.accuracy()</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bgd.nn.NeuralStack.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#NeuralStack.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.NeuralStack.train" title="Permalink to this definition"></a></dt>
<dd><p>Trains the model on samples X and labels y. Optimize the model
parameters so that the loss is minimized on this dataset.
The validation fraction <em>must</em> be in [0, 1] (0 to not evaluate the
model on a validation set).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – Array of samples. <cite>shape == (n_instances, n_features)</cite> or
<cite>shape == (n_instances, n_pixels, n_channels)</cite> for images.</p></li>
<li><p><strong>y</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – Array of labels. <cite>shape == (n_instances,)</cite></p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of times the dataset (X, y) is entirely fed to the model.</p></li>
<li><p><strong>l2_alpha</strong> (<em>float</em>) – L2 regularization alpha parameter (0 if no L2).</p></li>
<li><p><strong>print_every</strong> (<em>int</em>) – Number of batches between two prints of model state and
evaluations on the intermediate validation set (negative
number if none is wanted). Defaults to 1.</p></li>
<li><p><strong>validation_fraction</strong> (<em>float</em>) – Proportion of samples to be kept for validation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>errors:</dt><dd><p>array of the loss of each batch.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – see <a class="reference internal" href="#bgd.nn.split_train_val" title="bgd.nn.split_train_val"><code class="xref py py-func docutils literal notranslate"><span class="pre">split_train_val()</span></code></a>.</p></li>
<li><p><a class="reference internal" href="bgd.errors.html#bgd.errors.RequiredComponentError" title="bgd.errors.RequiredComponentError"><strong>RequiredComponentError</strong></a> – see <a class="reference internal" href="#bgd.nn.NeuralStack.check_components" title="bgd.nn.NeuralStack.check_components"><code class="xref py py-meth docutils literal notranslate"><span class="pre">check_components()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_in</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_out</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span> <span class="o">=</span> <span class="n">NeuralStack</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">FullyConnected</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">FullyConnected</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_out</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">CrossEntropy</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">AdamOptimizer</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SGDBatching</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">losses</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">Loss at epoch 49 (batch 2): 1.2941039726880612   - Validation accuracy: 83.333%</span>
<span class="go">Loss at epoch 99 (batch 2): 0.764482839362229    - Validation accuracy: 96.111%</span>
<span class="go">Loss at epoch 149 (batch 2): 0.5154527368075816   - Validation accuracy: 97.222%</span>
<span class="go">Loss at epoch 199 (batch 2): 0.3979498104086121   - Validation accuracy: 97.778%</span>
<span class="go">Loss at epoch 249 (batch 2): 0.32569535096131924  - Validation accuracy: 97.778%</span>
<span class="go">Loss at epoch 299 (batch 2): 0.2748402661346476   - Validation accuracy: 97.778%</span>
<span class="go">Loss at epoch 349 (batch 2): 0.2555267910622358   - Validation accuracy: 97.778%</span>
<span class="go">Loss at epoch 399 (batch 2): 0.22863001357754167  - Validation accuracy: 97.778%</span>
<span class="go">Loss at epoch 449 (batch 2): 0.22746067257186584  - Validation accuracy: 97.778%</span>
<span class="go">Loss at epoch 499 (batch 2): 0.22220948073377536  - Validation accuracy: 97.778%</span>
<span class="go">Loss at epoch 549 (batch 2): 0.2089401746378744   - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 599 (batch 2): 0.20035077161054704  - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 649 (batch 2): 0.1867468456143161   - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 699 (batch 2): 0.17347271604108705  - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 749 (batch 2): 0.15376433332896908  - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 799 (batch 2): 0.15436015140582668  - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 849 (batch 2): 0.13860411664942396  - Validation accuracy: 98.889%</span>
<span class="go">Loss at epoch 899 (batch 2): 0.133165375570591    - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 949 (batch 2): 0.12890010110436428  - Validation accuracy: 98.333%</span>
<span class="go">Loss at epoch 999 (batch 2): 0.12433454132628034  - Validation accuracy: 98.333%</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loss over time:&#39;</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<span class="go">Errors: [ 2.50539121  2.28391007  2.40779468 ...,  0.11655055  0.12436938  0.09155006]</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bgd.nn.binarize_labels">
<span class="sig-prename descclassname"><span class="pre">bgd.nn.</span></span><span class="sig-name descname"><span class="pre">binarize_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#binarize_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.binarize_labels" title="Permalink to this definition"></a></dt>
<dd><p>Transforms a N-valued vector of labels into a binary vector.
If N classes are present, they <em>must</em> be 0 to N-1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – Vector of classes.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>binary_y:</dt><dd><p>Binary matrix of shape (n_instances, n_classes)
s.t. <cite>binary_y[i,j] == 1</cite> iff <cite>y[i] == j</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binarize_labels</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">array([[1, 0],</span>
<span class="go">       [0, 1],</span>
<span class="go">       [1, 0],</span>
<span class="go">       [1, 0],</span>
<span class="go">       [0, 1],</span>
<span class="go">       [0, 1],</span>
<span class="go">       [1, 0]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bgd.nn.split_train_val">
<span class="sig-prename descclassname"><span class="pre">bgd.nn.</span></span><span class="sig-name descname"><span class="pre">split_train_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_fraction</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bgd/nn.html#split_train_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bgd.nn.split_train_val" title="Permalink to this definition"></a></dt>
<dd><p>Splits randomly the dataset (X, y) into a training set
and a validation set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – Matrix of samples. shape == (n_instances, n_features).</p></li>
<li><p><strong>y</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – Vector of expected outputs. shape == (n_instances,)
or (n_instances, n_classes) if binarized.</p></li>
<li><p><strong>validation_fraction</strong> (<em>float</em>) – Proportion of samples to be kept for validation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>X_train (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>):</dt><dd><p>Matrix of training samples.
len(X_train) == len(X) * (1 - validation_fraction)</p>
</dd>
<dt>y_train (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>):</dt><dd><p>Vector of training expected outputs.
len(y_train) == len(y) * (1 - validation_fraction)</p>
</dd>
<dt>X_test (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>):</dt><dd><p>Matrix of test samples.
len(X_test) == len(X) * validation_fraction</p>
</dd>
<dt>y_test (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>):</dt><dd><p>Vector of test expected outputs.
len(y_test) == len(y) * validation_fraction</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If validation_fraction is not in [0, 1].</p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bgd.initializers.html" class="btn btn-neutral float-left" title="bgd.initializers module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bgd.optimizers.html" class="btn btn-neutral float-right" title="bgd.optimizers module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, Antoine Passemiers and Robin Petit.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>